api_name: []
items:
- _type: class
  children:
  - cntk.learners.UserLearner.update
  class: cntk.learners.UserLearner
  fullName: cntk.learners.UserLearner
  inheritance:
  - - cntk.cntk_py.Learner
    - builtins.object
  module: cntk.learners
  name: UserLearner
  references:
  - fullName: cntk.learners.UserLearner.update
    isExternal: false
    name: update
    parent: ''
    uid: cntk.learners.UserLearner.update
  source:
    id: UserLearner
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/learners/__init__.py
    remote:
      branch: '/bin/sh: 1: git: not found'
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/learners/__init__.py
      repo: null
    startLine: 160
  syntax:
    summary: 'Bases: `cntk.cntk_py.Learner`

      Base class of all user-defined learners. To implement your own learning algorithm,
      derive from this class and override the `update()`.

      Certain optimizers (such as AdaGrad) require additional storage. This can be
      allocated and initialized during construction.

      '
  type: Class
  uid: cntk.learners.UserLearner
- _type: method
  class: cntk.learners.UserLearner
  fullName: cntk.learners.UserLearner.update
  module: cntk.learners
  name: update
  source:
    id: update
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/learners/__init__.py
    remote:
      branch: '/bin/sh: 1: git: not found'
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/learners/__init__.py
      repo: null
    startLine: 201
  syntax:
    exceptions: []
    parameters:
    - description: maps `Parameter` to a NumPy array containing the first order gradient
        values for the Parameter w.r.t. the training objective.
      id: training_sample_count
      type: int
    - description: number of samples in the minibatch
      id: sweep_end
      type: bool
    - description: if the data is fed by a conforming reader, this indicates whether
        a full pass over the dataset has just occured.
      id: gradient_values
      type: dict
    returntype: ''
    returnvalue: '*False* to indicate that learning has stopped for all of the parameters
      associated with this learner'
    summary: Update the parameters associated with this learner.
    variables: []
  type: Method
  uid: cntk.learners.UserLearner.update
