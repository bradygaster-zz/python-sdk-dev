api_name: []
items:
- _type: module
  children:
  - cntk.layers.layers.Activation
  - cntk.layers.layers.AveragePooling
  - cntk.layers.layers.BatchNormalization
  - cntk.layers.layers.Convolution
  - cntk.layers.layers.Convolution1D
  - cntk.layers.layers.Convolution2D
  - cntk.layers.layers.Convolution3D
  - cntk.layers.layers.ConvolutionTranspose
  - cntk.layers.layers.ConvolutionTranspose1D
  - cntk.layers.layers.ConvolutionTranspose2D
  - cntk.layers.layers.ConvolutionTranspose3D
  - cntk.layers.layers.Dense
  - cntk.layers.layers.Dropout
  - cntk.layers.layers.Embedding
  - cntk.layers.layers.GlobalAveragePooling
  - cntk.layers.layers.GlobalMaxPooling
  - cntk.layers.layers.Label
  - cntk.layers.layers.LayerNormalization
  - cntk.layers.layers.MaxPooling
  - cntk.layers.layers.MaxUnpooling
  fullName: cntk.layers.layers
  langs:
  - python
  module: cntk.layers.layers
  name: layers
  source:
    id: layers
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 0
  summary: ''
  type: Namespace
  uid: cntk.layers.layers
- _type: function
  fullName: cntk.layers.layers.Activation
  langs:
  - python
  module: cntk.layers.layers
  name: Activation
  source:
    id: Activation
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1058
  summary: 'Layer factory function to create an activation layer. Activation functions
    can be used directly in CNTK, so there is no difference between `y = relu(x)`
    and `y = Activation(relu)(x)`. This layer is useful if one wants to configure
    the activation function with `default_options`, or when its invocation should
    be named.

    -[ Example ]-

    >>> model = Dense(500) >> Activation(C.relu) >> Dense(10)

    >>> # is the same as

    >>> model = Dense(500) >> C.relu >> Dense(10)

    >>> # and also the same as

    >>> model = Dense(500, activation=C.relu) >> Dense(10)'
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0160>
      description: function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Activation
- _type: function
  fullName: cntk.layers.layers.AveragePooling
  langs:
  - python
  module: cntk.layers.layers
  name: AveragePooling
  source:
    id: AveragePooling
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 888
  summary: "Layer factory function to create an average-pooling layer.\nLike `Convolution()`,\
    \ `AveragePooling()` processes items arranged on an N-dimensional grid, such as\
    \ an image. Typically, each item is a vector. For each item, average-pooling computes\
    \ the element-wise mean over a window (\"receptive field\") of items surrounding\
    \ the item's position on the grid.\nThe size (spatial extent) of the receptive\
    \ field is given by `filter_shape`. E.g. for 2D pooling, `filter_shape` should\
    \ be a tuple of two integers, such as *(5,5)*.\n-[ Example ]-\n>>> f = AveragePooling((3,3),\
    \ strides=2)  # reduce dimensionality by 2, pooling over windows of 3x3\n>>> h\
    \ = Input((32,240,320))  # e.g. 32-dim feature map\n>>> hp = f(h)\n>>> hp.shape\
    \  # spatial dimension has been halved due to stride, and lost one due to 3x3\
    \ window without padding\n    (32, 119, 159)\n>>> f = AveragePooling((2,2), strides=2)\n\
    >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3],\
    \ [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for simplicity)\n\
    >>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n            [1,\
    \ 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])  # due to strides=2, this\
    \ computes the averages of each 2x2 sub-block\n    array([[[[[ 3.5 ,  4.75],\n\
    \              [ 4.25,  6.25]]]]], dtype=float32)"
  syntax:
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: ''
      description: stride (increment when sliding over the input). Use a *tuple* to
        specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5c00b8>
      description: if *False*, then the pooling operation will be shifted over the
        "valid" area of input, that is, no value outside the area is used. If `pad=True`
        on the other hand, pooling will be applied to all input positions, and positions
        outside the valid region will be excluded from the averaging. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: '1'
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the average-pooling
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.AveragePooling
- _type: function
  fullName: cntk.layers.layers.BatchNormalization
  langs:
  - python
  module: cntk.layers.layers
  name: BatchNormalization
  source:
    id: BatchNormalization
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1091
  summary: "Layer factory function to create a batch-normalization layer.\nBatch normalization\
    \ applies this formula to every input element (element-wise): `y = (x - batch_mean)\
    \ / (batch_stddev + epsilon) * scale + bias` where `batch_mean` and `batch_stddev`\
    \ are estimated on the minibatch and `scale` and `bias` are learned parameters.\
    \ TODO: add paper reference\nDuring operation, this layer also estimates an aggregate\
    \ running mean and standard deviation for use in inference.\nA `BatchNormalization`\
    \ layer instance owns its learnable parameter tensors and exposes them as attributes\
    \ `.scale` and `.bias`. The aggregate estimates are exposed as attributes `aggregate_mean`,\
    \ `aggregate_variance`, and `aggregate_count`.\n-[ Example ]-\n>>> # BatchNorm\
    \ on an image with spatial pooling\n>>> f = BatchNormalization(map_rank=1)\n>>>\
    \ f.update_signature((3,480,640))\n>>> f.bias.shape, f.scale.shape  # due to spatial\
    \ pooling (map_rank=1), there are only 3 biases and scales, shared across all\
    \ pixel positions\n    ((3,), (3,))"
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0240>
      id: map_rank
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0208>
      description: passing 1 means spatially-pooled batch-normalization, where normalization
        values will be tied across all pixel positions; while `None` will normalize
        all elements of the input tensor independently
      id: map_rank
      type: 1 or None
    - default: '0'
      description: initial value for the `scale` parameter
      id: init_scale
      type: float, default 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5c01d0>
      description: time constant for smoothing the batch statistics in order to compute
        aggregate estimates for inference.
      id: normalization_time_constant
      type: int, default 5000
    - default: '1'
      description: epsilon added to the variance to avoid division by 0
      id: epsilon
      type: float, default 0.00001
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0198>
      description: if `True` then use CNTK's own engine instead of NVidia's.
      id: use_cntk_engine
      type: bool, default False
    - description: the name of the function instance in the network
      id: name
      type: str, optional
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.BatchNormalization
- _type: function
  fullName: cntk.layers.layers.Convolution
  langs:
  - python
  module: cntk.layers.layers
  name: Convolution
  source:
    id: Convolution
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 251
  summary: "Layer factory function to create a convolution layer.\nThis implements\
    \ a convolution operation over items arranged on an N-dimensional grid, such as\
    \ pixels in an image. Typically, each item is a vector (e.g. pixel: R,G,B), and\
    \ the result is, in turn, a vector. The item-grid dimensions are referred to as\
    \ the *spatial* dimensions (e.g. dimensions of an image), while the vector dimension\
    \ of the individual items is often called *feature-map depth*.\nFor each item,\
    \ convolution gathers a window (\"receptive field\") of items surrounding the\
    \ item's position on the grid, and applies a little fully-connected network to\
    \ it (the same little network is applied to all item positions). The size (spatial\
    \ extent) of the receptive field is given by `filter_shape`. E.g. to specify a\
    \ 2D convolution, `filter_shape` should be a tuple of two integers, such as *(5,5)*;\
    \ an example for a 3D convolution (e.g. video or an MRI scan) would be `filter_shape=(3,3,3)`;\
    \ while for a 1D convolution (e.g. audio or text), `filter_shape` has one element,\
    \ such as (3,) or just 3.\nThe dimension of the input items (input feature-map\
    \ depth) is not to be specified. It is known from the input. The dimension of\
    \ the output items (output feature-map depth) generated for each item position\
    \ is given by `num_filters`.\nIf the input is a sequence, the sequence elements\
    \ are by default treated independently. To convolve along the sequence dimension\
    \ as well, pass `sequential=True`. This is useful for variable-length inputs,\
    \ such as video or natural-language processing (word n-grams). Note, however,\
    \ that convolution does not support sparse inputs.\nBoth input and output items\
    \ can be scalars intead of vectors. For scalar-valued input items, such as pixels\
    \ on a black-and-white image, or samples of an audio clip, specify `reduction_rank=0`.\
    \ If the output items are scalar, pass `num_filters=()` or `None`.\nA `Convolution`\
    \ instance owns its weight parameter tensors *W* and *b*, and exposes them as\
    \ an attributes `.W` and `.b`. The weights will have the shape `(num_filters,\
    \ input_feature_map_depth, *filter_shape)`\n-[ Example ]-\n>>> # 2D convolution\
    \ of 5x4 receptive field with output feature-map depth 128:\n>>> f = Convolution((5,4),\
    \ 128, activation=C.relu)\n>>> x = Input((3,480,640))  # 3-channel color image\n\
    >>> h = f(x)\n>>> h.shape\n    (128, 476, 637)\n>>> f.W.shape  # will have the\
    \ form (num_filters, input_depth, *filter_shape)\n    (128, 3, 5, 4)\n>>> # 2D\
    \ convolution over a one-channel black-and-white image, padding, and stride 2\
    \ along width dimension\n>>> f = Convolution((3,3), 128, reduction_rank=0, pad=True,\
    \ strides=(1,2), activation=C.relu)\n>>> x = Input((480,640))\n>>> h = f(x)\n\
    >>> h.shape\n    (128, 480, 319)\n>>> f.W.shape\n    (128, 1, 3, 3)\n>>> # 3D\
    \ convolution along dynamic axis over a sequence of 2D color images\n>>> from\
    \ cntk.layers.typing import Sequence, Tensor\n>>> f = Convolution((2,5,4), 128,\
    \ sequential=True, activation=C.relu) # over 2 consecutive frames\n>>> x = Input(**Sequence[Tensor[3,480,640]])\
    \  # a variable-length video of 640x480 RGB images\n>>> h = f(x)\n>>> h.shape\
    \   # this is the shape per video frame: 637x476 activation vectors of length\
    \ 128 each\n    (128, 476, 637)\n>>> f.W.shape # (output featuer map depth, input\
    \ depth, and the three filter dimensions)\n    (128, 3, 2, 5, 4)"
  syntax:
    parameters:
    - id: filter_shape
    - default: ''
      description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: Convolution
      description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int, defaults to None
    - default: '0'
      description: if *True*, also convolve along the dynamic axis. `filter_shape[0]`
        corresponds to dynamic axis.
      id: sequential
      type: bool, defaults to False
    - default: 'False'
      description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - default: '1'
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: <cntk.default_options.default_override_or object at 0x2afede5b56d8>
      description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: <cntk.default_options.default_override_or object at 0x2afede5b56a0>
      description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: 'True'
      description: When *True*, every position uses the same Convolution kernel.  When
        *False*, you can have a different Convolution kernel per position, but *False*
        is not supported.
      id: sharing
      type: bool, defaults to True
    - default: '1'
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, optional, defaults to True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5668>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5630>
      description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: reduction_rank
      type: int, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5b55c0>
      description: When this is *True* this is deconvolution
      id: transpose
      type: bool, defaults to False
    - default: 'False'
      description: Limits the amount of memory for intermiadate convolution results.  A
        value of 0 means, memory is automatically managed.
      id: max_temp_mem_size_in_samples
      type: int, defaults to 0
    - default: None
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the convolution
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Convolution
- _type: function
  fullName: cntk.layers.layers.Convolution1D
  langs:
  - python
  module: cntk.layers.layers
  name: Convolution1D
  source:
    id: Convolution1D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 454
  summary: Layer factory function to create a 1D convolution layer with optional non-linearity.
    Same as *Convolution()* except that filter_shape is verified to be 1-dimensional.
    See *Convolution()* for extensive documentation.
  syntax:
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: ''
      description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int, defaults to None
    - default: '1'
      description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5828>
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: <cntk.default_options.default_override_or object at 0x2afede5b57f0>
      description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: '1'
      description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5b57b8>
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, defaults to True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5780>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5710>
      description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: reduction_rank
      type: int, defaults to 1
    - default: None
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the convolution
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Convolution1D
- _type: function
  fullName: cntk.layers.layers.Convolution2D
  langs:
  - python
  module: cntk.layers.layers
  name: Convolution2D
  source:
    id: Convolution2D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 503
  summary: Layer factory function to create a 2D convolution layer with optional non-linearity.
    Same as *Convolution()* except that filter_shape is verified to be 2-dimensional.
    See *Convolution()* for extensive documentation.
  syntax:
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: ''
      description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int, defaults to None
    - default: '1'
      description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5978>
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5940>
      description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: '1'
      description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5908>
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, defaults to True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b58d0>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5860>
      description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: reduction_rank
      type: int, defaults to 1
    - default: None
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the convolution
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Convolution2D
- _type: function
  fullName: cntk.layers.layers.Convolution3D
  langs:
  - python
  module: cntk.layers.layers
  name: Convolution3D
  source:
    id: Convolution3D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 553
  summary: Layer factory function to create a 3D convolution layer with optional non-linearity.
    Same as *Convolution()* except that filter_shape is verified to be 3-dimensional.
    See *Convolution()* for extensive documentation.
  syntax:
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: ''
      description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int, defaults to None
    - default: '1'
      description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5ac8>
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5a90>
      description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: '1'
      description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5a58>
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, defaults to True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5a20>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b59b0>
      description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: reduction_rank
      type: int, defaults to 1
    - default: None
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the convolution
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Convolution3D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose
  langs:
  - python
  module: cntk.layers.layers
  name: ConvolutionTranspose
  source:
    id: ConvolutionTranspose
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 605
  summary: "Layer factory function to create a convolution transpose layer.\nThis\
    \ implements a convolution_transpose operation over items arranged on an N-dimensional\
    \ grid, such as pixels in an image. Typically, each item is a vector (e.g. pixel:\
    \ R,G,B), and the result is, in turn, a vector. The item-grid dimensions are referred\
    \ to as the *spatial* dimensions (e.g. dimensions of an image), while the vector\
    \ dimensions of the individual items are often called *feature-map depth*.\nConvolution\
    \ transpose is also known as `fractionally strided convolutional layers`, or,\
    \ `deconvolution`. This operation is used in image and language processing applications.\
    \ It supports arbitrary dimensions, strides, and padding.\nThe forward and backward\
    \ computation of convolution transpose is the inverse of convolution. That is,\
    \ during forward pass the input layer's items are spread into the output same\
    \ as the backward spread of gradients in convolution. The backward pass, on the\
    \ other hand, performs a convolution same as the forward pass of convolution.\n\
    The size (spatial extent) of the receptive field for convolution transpose is\
    \ given by `filter_shape`. E.g. to specify a 2D convolution transpose, `filter_shape`\
    \ should be a tuple of two integers, such as *(5,5)*; an example for a 3D convolution\
    \ transpose (e.g. video or an MRI scan) would be `filter_shape=(3,3,3)`; while\
    \ for a 1D convolution transpose (e.g. audio or text), `filter_shape` has one\
    \ element, such as (3,).\nThe dimension of the input items (feature-map depth)\
    \ is not specified, but known from the input. The dimension of the output items\
    \ generated for each item position is given by `num_filters`.\nA `ConvolutionTranspose`\
    \ instance owns its weight parameter tensors *W* and *b*, and exposes them as\
    \ an attributes `.W` and `.b`. The weights will have the shape `(input_feature_map_depth,\
    \ num_filters, *filter_shape)`.\n-[ Example ]-\n>>> # 2D convolution transpose\
    \ of 3x4 receptive field with output feature-map depth 128:\n>>> f = ConvolutionTranspose((3,4),\
    \ 128, activation=C.relu)\n>>> x = Input((3,480,640))  # 3-channel color image\n\
    >>> h = f(x)\n>>> h.shape\n    (128, 482, 643)\n>>> f.W.shape  # will have the\
    \ form (input_depth, num_filters, *filter_shape)\n    (3, 128, 3, 4)"
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5b00>
      description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int
    - description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, optional
    - default: ''
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, default glorot_uniform()
    - default: '0'
      description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, default False
    - default: '1'
      description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: strides
      type: int or tuple of ints, default 1
    - default: None
      description: weight sharing, must be True for now.
      id: sharing
      type: bool, default True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5c18>
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, optional, default True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5be0>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer
    - default: 'True'
      description: output shape. When strides > 2, the output shape is non-deterministic.
        User can specify the wanted output shape. Note the specified shape must satisify
        the condition that if a convolution is perform from the output with the same
        setting, the result must have same shape as the input.
      id: output_shape
      type: int or tuple of ints
    - default: '1'
      description: must be 1 for now. that is stored with tensor shape (H,W) instead
        of (1,H,W)
      id: reduction_rank
      type: int, default 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5ba8>
      description: set to a positive number to define the maximum workspace memory
        for convolution.
      id: max_temp_mem_size_in_samples
      type: int, default 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5b70>
      description: the name of the Function instance in the network
      id: name
      type: str, optional
    return:
      description: '`Function` that accepts one argument and applies the convolution
        operation to it'
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose1D
  langs:
  - python
  module: cntk.layers.layers
  name: ConvolutionTranspose1D
  source:
    id: ConvolutionTranspose1D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 731
  summary: Layer factory function to create a 1D convolution transpose layer with
    optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
    is verified to be 1-dimensional. See *ConvolutionTranspose()* for extensive documentation.
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5c50>
      id: filter_shape
    - id: num_filters
    - id: activation
    - default: ''
      id: init
    - default: None
      id: pad
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5d68>
      id: strides
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5d30>
      id: bias
    - default: '1'
      id: init_bias
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5cf8>
      id: output_shape
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5cc0>
      id: name
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose1D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose2D
  langs:
  - python
  module: cntk.layers.layers
  name: ConvolutionTranspose2D
  source:
    id: ConvolutionTranspose2D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 757
  summary: Layer factory function to create a 2D convolution transpose layer with
    optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
    is verified to be 2-dimensional. See *ConvolutionTranspose()* for extensive documentation.
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5da0>
      id: filter_shape
    - id: num_filters
    - id: activation
    - default: ''
      id: init
    - default: None
      id: pad
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5eb8>
      id: strides
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5e80>
      id: bias
    - default: '1'
      id: init_bias
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5e48>
      id: output_shape
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5e10>
      id: name
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose2D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose3D
  langs:
  - python
  module: cntk.layers.layers
  name: ConvolutionTranspose3D
  source:
    id: ConvolutionTranspose3D
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 784
  summary: Layer factory function to create a 3D convolution transpose layer with
    optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
    is verified to be 3-dimensional. See *ConvolutionTranspose()* for extensive documentation.
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5ef0>
      id: filter_shape
    - id: num_filters
    - id: activation
    - default: ''
      id: init
    - default: None
      id: pad
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0048>
      id: strides
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5fd0>
      id: bias
    - default: '1'
      id: init_bias
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5f98>
      id: output_shape
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5f60>
      id: name
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose3D
- _type: function
  fullName: cntk.layers.layers.Dense
  langs:
  - python
  module: cntk.layers.layers
  name: Dense
  source:
    id: Dense
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 23
  summary: "Layer factory function to create an instance of a fully-connected linear\
    \ layer of the form *activation(input @ W + b)* with weights *W* and bias *b*,\
    \ and *activation* and *b* being optional. *shape* may describe a tensor as well.\n\
    A `Dense` layer instance owns its parameter tensors *W* and *b*, and exposes them\
    \ as attributes `.W` and `.b`.\n-[ Example ]-\n>>> f = Dense(5, activation=C.relu)\n\
    >>> x = Input(3)\n>>> h = f(x)\n>>> h.shape\n    (5,)\n>>> f.W.shape\n    (3,\
    \ 5)\n>>> f.b.value\n    array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)\n>>>\
    \ # activation through default options\n>>> with default_options(activation=C.relu):\n\
    ...     f = Dense(500)"
  syntax:
    parameters:
    - description: vector or tensor dimension of the output of this layer
      id: shape
      type: int or tuple of ints
    - default: ''
      description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - default: <cntk.default_options.default_override_or object at 0x2afede5b54e0>
      description: initial value of weights *W*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: <cntk.default_options.default_override_or object at 0x2afede5b54a8>
      description: number of inferred axes to add to W (*map_rank* must not be given)
      id: input_rank
      type: int, defaults to None
    - default: None
      description: expand W to leave exactly *map_rank* axes (*input_rank* must not
        be given)
      id: map_rank
      type: int, defaults to None
    - default: None
      description: the layer will have no bias if *False* is passed here
      id: bias
      type: bool, optional, defaults to True
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5470>
      description: initial value of weights *b*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defualts to 0
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5400>
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Dense
- _type: function
  fullName: cntk.layers.layers.Dropout
  langs:
  - python
  module: cntk.layers.layers
  name: Dropout
  source:
    id: Dropout
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1020
  summary: 'Layer factory function to create a drop-out layer.

    The dropout rate can be specified as the probability of *dropping* a value (`dropout_rate`).
    E.g. `Dropout(0.3)` means "drop 30% o the activation values." Alternatively, it
    can also be specified as the probability of *keeping* a value (`keep_prob`).

    -[ Example ]-

    >>> f = Dropout(0.2)   # "drop 20% of activations"

    >>> h = Input(3)

    >>> hd = f(h)

    >>> f = Dropout(keep_prob=0.8)   # "keep 80%"

    >>> h = Input(3)

    >>> hd = f(h)'
  syntax:
    parameters:
    - default: None
      description: probability of dropping out an element, mutually exclusive with
        `keep_prob`
      id: dropout_rate
      type: float
    - default: None
      description: probability of keeping an element, mutually exclusive with `dropout_rate`
      id: keep_prob
      type: float
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Dropout
- _type: function
  fullName: cntk.layers.layers.Embedding
  langs:
  - python
  module: cntk.layers.layers
  name: Embedding
  source:
    id: Embedding
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 115
  summary: "Embedding(shape=None, init=glorot_uniform(), weights=None, name=''):\n\
    Layer factory function to create a embedding layer.\nAn embedding is conceptually\
    \ a lookup table. For every input token (e.g. a word or any category label), the\
    \ corresponding entry in in the lookup table is returned.\nIn CNTK, discrete items\
    \ such as words are represented as one-hot vectors. The table lookup is realized\
    \ as a matrix product, with a matrix whose rows are the embedding vectors. Note\
    \ that multiplying a matrix from the left with a one-hot vector is the same as\
    \ copying out the row for which the input vector is 1. CNTK has special optimizations\
    \ to make this operation as efficient as an actual table lookup if the input is\
    \ sparse.\nThe lookup table in this layer is learnable, unless a user-specified\
    \ one is supplied through the `weights` parameter. For example, to use an existing\
    \ embedding table from a file in numpy format, use this:\n<!-- literal_block {\"\
    backrefs\": [], \"names\": [], \"dupnames\": [], \"xml:space\": \"preserve\",\
    \ \"classes\": [], \"ids\": []} -->\n\n````\n\n   Embedding(weights=np.load('PATH.npy'))\n\
    \   ````\nTo initialize a learnable lookup table with a given numpy array that\
    \ is to be used as the initial value, pass that array to the `init` parameter\
    \ (not `weights`).\nAn `Embedding` instance owns its weight parameter tensor *E*,\
    \ and exposes it as an attribute `.E`.\n-[ Example ]-\n>>> # learnable embedding\n\
    >>> f = Embedding(5)\n>>> x = Input(3)\n>>> e = f(x)\n>>> e.shape\n    (5,)\n\
    >>> f.E.shape\n    (3, 5)\n>>> # user-supplied embedding\n>>> f = Embedding(weights=[[.5,\
    \ .3, .1, .4, .2], [.7, .6, .3, .2, .9]])\n>>> f.E.value\n    array([[ 0.5,  0.3,\
    \  0.1,  0.4,  0.2],\n           [ 0.7,  0.6,  0.3,  0.2,  0.9]], dtype=float32)\n\
    >>> x = Input(2, is_sparse=True)\n>>> e = f(x)\n>>> e.shape\n    (5,)\n>>> e(C.one_hot([[1],\
    \ [0], [0], [1]], num_classes=2))\narray([[[ 0.7,  0.6,  0.3,  0.2,  0.9]],\n\
    <BLANKLINE>\n       [[ 0.5,  0.3,  0.1,  0.4,  0.2]],\n<BLANKLINE>\n       [[\
    \ 0.5,  0.3,  0.1,  0.4,  0.2]],\n<BLANKLINE>\n       [[ 0.7,  0.6,  0.3,  0.2,\
    \  0.9]]], dtype=float32)"
  syntax:
    parameters:
    - default: None
      description: vector or tensor dimension of the output of this layer
      id: shape
      type: int or tuple of ints
    - default: <cntk.default_options.default_override_or object at 0x2afede5b5550>
      description: (learnable embedding only) initial value of weights *E*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - default: None
      description: (user-supplied embedding only) the lookup table. The matrix rows
        are the embedding vectors, `weights[i,:]` being the embedding that corresponds
        to input category *i*.
      id: weights
      type: NumPy array, mutually exclusive with init, defuats to None
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the embedding
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Embedding
- _type: function
  fullName: cntk.layers.layers.GlobalAveragePooling
  langs:
  - python
  module: cntk.layers.layers
  name: GlobalAveragePooling
  source:
    id: GlobalAveragePooling
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 970
  summary: "Layer factory function to create a global average-pooling layer.\nThe\
    \ global average-pooling operation computes the element-wise mean over all items\
    \ on an N-dimensional grid, such as an image.\nThis operation is the same as applying\
    \ `reduce_mean()` to all grid dimensions.\n-[ Example ]-\n>>> f = GlobalAveragePooling()\n\
    >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3],\
    \ [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for simplicity)\n\
    >>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n            [1,\
    \ 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])\n    array([[[[[ 4.6875]]]]],\
    \ dtype=float32)"
  syntax:
    parameters:
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.GlobalAveragePooling
- _type: function
  fullName: cntk.layers.layers.GlobalMaxPooling
  langs:
  - python
  module: cntk.layers.layers
  name: GlobalMaxPooling
  source:
    id: GlobalMaxPooling
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 940
  summary: "Layer factory function to create a global max-pooling layer.\nThe global\
    \ max-pooling operation computes the element-wise maximum over all items on an\
    \ N-dimensional grid, such as an image.\nThis operation is the same as applying\
    \ `reduce_max()` to all grid dimensions.\n-[ Example ]-\n>>> f = GlobalMaxPooling()\n\
    >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3],\
    \ [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for simplicity)\n\
    >>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n            [1,\
    \ 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])\n    array([[[[[ 9.]]]]],\
    \ dtype=float32)"
  syntax:
    parameters:
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.GlobalMaxPooling
- _type: function
  fullName: cntk.layers.layers.Label
  langs:
  - python
  module: cntk.layers.layers
  name: Label
  source:
    id: Label
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1202
  summary: "Layer factory function to create a dummy layer with a given name. This\
    \ can be used to access an intermediate value flowing through computation.\n-[\
    \ Example ]-\n>>> model = Dense(500) >> Label('hidden') >> Dense(10)\n>>> model.update_signature(10)\n\
    >>> intermediate_val = model.hidden\n>>> intermediate_val.shape\n    (500,)"
  syntax:
    parameters:
    - id: name
    return:
      description: A function that accepts one argument and returns it with the desired
        name attached
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.Label
- _type: function
  fullName: cntk.layers.layers.LayerNormalization
  langs:
  - python
  module: cntk.layers.layers
  name: LayerNormalization
  source:
    id: LayerNormalization
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1156
  summary: "Layer factory function to create a function that implements layer normalization.\n\
    Layer normalization applies this formula to every input element (element-wise):\
    \ `y = (x - mean(x)) / (stddev(x) + epsilon) * scale + bias` where `scale` and\
    \ `bias` are learned scalar parameters. TODO: add paper reference\n-[ Example\
    \ ]-\n>>> f = LayerNormalization(initial_scale=2, initial_bias=1)\n>>> f.update_signature(4)\n\
    >>> f([np.array([[4,0,0,4]])])  # result has mean 1 and standard deviation 2,\
    \ reflecting the initial values for scale and bias\n    array([[[ 2.99999, -0.99999,\
    \ -0.99999,  2.99999]]], dtype=float32)"
  syntax:
    parameters:
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0278>
      description: initial value for the `scale` parameter
      id: initial_scale
      type: float, default 1
    - default: '0'
      description: initial value for the `bias` parameter
      id: initial_bias
      type: float, default 0
    - default: '1'
      description: epsilon added to the standard deviation to avoid division by 0
      id: epsilon
      type: float, default 0.00001
    - description: the name of the Function instance in the network
      id: name
      type: str, optional
    return:
      description: A function that accepts one argument and applies the operation
        to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.LayerNormalization
- _type: function
  fullName: cntk.layers.layers.MaxPooling
  langs:
  - python
  module: cntk.layers.layers
  name: MaxPooling
  source:
    id: MaxPooling
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 836
  summary: "Layer factory function to create a max-pooling layer.\nLike `Convolution()`,\
    \ `MaxPooling()` processes items arranged on an N-dimensional grid, such as an\
    \ image. Typically, each item is a vector. For each item, max-pooling computes\
    \ the element-wise maximum over a window (\"receptive field\") of items surrounding\
    \ the item's position on the grid.\nThe size (spatial extent) of the receptive\
    \ field is given by `filter_shape`. E.g. for 2D pooling, `filter_shape` should\
    \ be a tuple of two integers, such as *(5,5)*.\n-[ Example ]-\n>>> f = MaxPooling((3,3),\
    \ strides=2)  # reduce dimensionality by 2, pooling over windows of 3x3\n>>> h\
    \ = Input((32,240,320))  # e.g. 32-dim feature map\n>>> hp = f(h)\n>>> hp.shape\
    \  # spatial dimension has been halved due to stride, and lost one due to 3x3\
    \ window without padding\n    (32, 119, 159)\n>>> f = MaxPooling((2,2), strides=2)\n\
    >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8, 3],\
    \ [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for simplicity)\n\
    >>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n            [1,\
    \ 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])  # due to strides=2, this\
    \ picks the max out of each 2x2 sub-block\n    array([[[[[ 5.,  8.],\n       \
    \       [ 7.,  9.]]]]], dtype=float32)"
  syntax:
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: filter_shape
      type: int or tuple of ints
    - default: ''
      description: stride (increment when sliding over the input). Use a *tuple* to
        specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - default: <cntk.default_options.default_override_or object at 0x2afede5c0080>
      description: if *False*, then the pooling operation will be shifted over the
        "valid" area of input, that is, no value outside the area is used. If `pad=True`
        on the other hand, pooling will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: pad
      type: bool or tuple of bools, defaults to False
    - default: '1'
      description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    return:
      description: A function that accepts one argument and applies the max-pooling
        operation to it
      type: cntk.ops.functions.Function
  type: Method
  uid: cntk.layers.layers.MaxPooling
- _type: function
  fullName: cntk.layers.layers.MaxUnpooling
  langs:
  - python
  module: cntk.layers.layers
  name: MaxUnpooling
  source:
    id: MaxUnpooling
    path: cntk/layers/layers.py
    remote:
      branch: master
      path: cntk/layers/layers.py
      repo: https://github.com/Microsoft/CNTK
    startLine: 1002
  summary: ''
  syntax:
    parameters:
    - id: filter_shape
    - default: ''
      id: strides
    - default: '0'
      id: pad
    - default: '0'
      id: lower_pad
    - default: 'False'
      id: upper_pad
    - default: '1'
      id: name
  type: Method
  uid: cntk.layers.layers.MaxUnpooling
references:
- fullName: cntk.layers.layers.Activation
  isExternal: false
  name: Activation
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Activation
- fullName: cntk.layers.layers.AveragePooling
  isExternal: false
  name: AveragePooling
  parent: cntk.layers.layers
  uid: cntk.layers.layers.AveragePooling
- fullName: cntk.layers.layers.BatchNormalization
  isExternal: false
  name: BatchNormalization
  parent: cntk.layers.layers
  uid: cntk.layers.layers.BatchNormalization
- fullName: cntk.layers.layers.Convolution
  isExternal: false
  name: Convolution
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Convolution
- fullName: cntk.layers.layers.Convolution1D
  isExternal: false
  name: Convolution1D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Convolution1D
- fullName: cntk.layers.layers.Convolution2D
  isExternal: false
  name: Convolution2D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Convolution2D
- fullName: cntk.layers.layers.Convolution3D
  isExternal: false
  name: Convolution3D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Convolution3D
- fullName: cntk.layers.layers.ConvolutionTranspose
  isExternal: false
  name: ConvolutionTranspose
  parent: cntk.layers.layers
  uid: cntk.layers.layers.ConvolutionTranspose
- fullName: cntk.layers.layers.ConvolutionTranspose1D
  isExternal: false
  name: ConvolutionTranspose1D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.ConvolutionTranspose1D
- fullName: cntk.layers.layers.ConvolutionTranspose2D
  isExternal: false
  name: ConvolutionTranspose2D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.ConvolutionTranspose2D
- fullName: cntk.layers.layers.ConvolutionTranspose3D
  isExternal: false
  name: ConvolutionTranspose3D
  parent: cntk.layers.layers
  uid: cntk.layers.layers.ConvolutionTranspose3D
- fullName: cntk.layers.layers.Dense
  isExternal: false
  name: Dense
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Dense
- fullName: cntk.layers.layers.Dropout
  isExternal: false
  name: Dropout
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Dropout
- fullName: cntk.layers.layers.Embedding
  isExternal: false
  name: Embedding
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Embedding
- fullName: cntk.layers.layers.GlobalAveragePooling
  isExternal: false
  name: GlobalAveragePooling
  parent: cntk.layers.layers
  uid: cntk.layers.layers.GlobalAveragePooling
- fullName: cntk.layers.layers.GlobalMaxPooling
  isExternal: false
  name: GlobalMaxPooling
  parent: cntk.layers.layers
  uid: cntk.layers.layers.GlobalMaxPooling
- fullName: cntk.layers.layers.Label
  isExternal: false
  name: Label
  parent: cntk.layers.layers
  uid: cntk.layers.layers.Label
- fullName: cntk.layers.layers.LayerNormalization
  isExternal: false
  name: LayerNormalization
  parent: cntk.layers.layers
  uid: cntk.layers.layers.LayerNormalization
- fullName: cntk.layers.layers.MaxPooling
  isExternal: false
  name: MaxPooling
  parent: cntk.layers.layers
  uid: cntk.layers.layers.MaxPooling
- fullName: cntk.layers.layers.MaxUnpooling
  isExternal: false
  name: MaxUnpooling
  parent: cntk.layers.layers
  uid: cntk.layers.layers.MaxUnpooling
