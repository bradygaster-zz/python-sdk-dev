api_name: []
items:
- _type: module
  children:
  - cntk.layers.layers.Activation
  - cntk.layers.layers.AveragePooling
  - cntk.layers.layers.BatchNormalization
  - cntk.layers.layers.Convolution
  - cntk.layers.layers.Convolution1D
  - cntk.layers.layers.Convolution2D
  - cntk.layers.layers.Convolution3D
  - cntk.layers.layers.ConvolutionTranspose
  - cntk.layers.layers.ConvolutionTranspose1D
  - cntk.layers.layers.ConvolutionTranspose2D
  - cntk.layers.layers.ConvolutionTranspose3D
  - cntk.layers.layers.Dense
  - cntk.layers.layers.Dropout
  - cntk.layers.layers.Embedding
  - cntk.layers.layers.GlobalAveragePooling
  - cntk.layers.layers.GlobalMaxPooling
  - cntk.layers.layers.Label
  - cntk.layers.layers.LayerNormalization
  - cntk.layers.layers.MaxPooling
  - cntk.layers.layers.MaxUnpooling
  fullName: cntk.layers.layers
  module: cntk.layers.layers
  name: layers
  references:
  - fullName: cntk.layers.layers.Activation
    isExternal: false
    name: Activation
    parent: ''
    uid: cntk.layers.layers.Activation
  - fullName: cntk.layers.layers.AveragePooling
    isExternal: false
    name: AveragePooling
    parent: ''
    uid: cntk.layers.layers.AveragePooling
  - fullName: cntk.layers.layers.BatchNormalization
    isExternal: false
    name: BatchNormalization
    parent: ''
    uid: cntk.layers.layers.BatchNormalization
  - fullName: cntk.layers.layers.Convolution
    isExternal: false
    name: Convolution
    parent: ''
    uid: cntk.layers.layers.Convolution
  - fullName: cntk.layers.layers.Convolution1D
    isExternal: false
    name: Convolution1D
    parent: ''
    uid: cntk.layers.layers.Convolution1D
  - fullName: cntk.layers.layers.Convolution2D
    isExternal: false
    name: Convolution2D
    parent: ''
    uid: cntk.layers.layers.Convolution2D
  - fullName: cntk.layers.layers.Convolution3D
    isExternal: false
    name: Convolution3D
    parent: ''
    uid: cntk.layers.layers.Convolution3D
  - fullName: cntk.layers.layers.ConvolutionTranspose
    isExternal: false
    name: ConvolutionTranspose
    parent: ''
    uid: cntk.layers.layers.ConvolutionTranspose
  - fullName: cntk.layers.layers.ConvolutionTranspose1D
    isExternal: false
    name: ConvolutionTranspose1D
    parent: ''
    uid: cntk.layers.layers.ConvolutionTranspose1D
  - fullName: cntk.layers.layers.ConvolutionTranspose2D
    isExternal: false
    name: ConvolutionTranspose2D
    parent: ''
    uid: cntk.layers.layers.ConvolutionTranspose2D
  - fullName: cntk.layers.layers.ConvolutionTranspose3D
    isExternal: false
    name: ConvolutionTranspose3D
    parent: ''
    uid: cntk.layers.layers.ConvolutionTranspose3D
  - fullName: cntk.layers.layers.Dense
    isExternal: false
    name: Dense
    parent: ''
    uid: cntk.layers.layers.Dense
  - fullName: cntk.layers.layers.Dropout
    isExternal: false
    name: Dropout
    parent: ''
    uid: cntk.layers.layers.Dropout
  - fullName: cntk.layers.layers.Embedding
    isExternal: false
    name: Embedding
    parent: ''
    uid: cntk.layers.layers.Embedding
  - fullName: cntk.layers.layers.GlobalAveragePooling
    isExternal: false
    name: GlobalAveragePooling
    parent: ''
    uid: cntk.layers.layers.GlobalAveragePooling
  - fullName: cntk.layers.layers.GlobalMaxPooling
    isExternal: false
    name: GlobalMaxPooling
    parent: ''
    uid: cntk.layers.layers.GlobalMaxPooling
  - fullName: cntk.layers.layers.Label
    isExternal: false
    name: Label
    parent: ''
    uid: cntk.layers.layers.Label
  - fullName: cntk.layers.layers.LayerNormalization
    isExternal: false
    name: LayerNormalization
    parent: ''
    uid: cntk.layers.layers.LayerNormalization
  - fullName: cntk.layers.layers.MaxPooling
    isExternal: false
    name: MaxPooling
    parent: ''
    uid: cntk.layers.layers.MaxPooling
  - fullName: cntk.layers.layers.MaxUnpooling
    isExternal: false
    name: MaxUnpooling
    parent: ''
    uid: cntk.layers.layers.MaxUnpooling
  source:
    id: layers
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 0
  type: Namespace
  uid: cntk.layers.layers
- _type: function
  fullName: cntk.layers.layers.Activation
  module: cntk.layers.layers
  name: Activation
  source:
    id: Activation
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1058
  syntax:
    exceptions: []
    parameters:
    - description: function to apply at the end, e.g. *relu*
      id: name
      type: str, defaults to ''
    - description: the name of the function instance in the network
      id: activation
      type: Function, defaults to identity
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: 'Layer factory function to create an activation layer. Activation functions
      can be used directly in CNTK, so there is no difference between `y = relu(x)`
      and `y = Activation(relu)(x)`. This layer is useful if one wants to configure
      the activation function with `default_options`, or when its invocation should
      be named.

      -[ Example ]-

      >>> model = Dense(500) >> Activation(C.relu) >> Dense(10)

      >>> # is the same as

      >>> model = Dense(500) >> C.relu >> Dense(10)

      >>> # and also the same as

      >>> model = Dense(500, activation=C.relu) >> Dense(10)'
    variables: []
  type: Method
  uid: cntk.layers.layers.Activation
- _type: function
  fullName: cntk.layers.layers.AveragePooling
  module: cntk.layers.layers
  name: AveragePooling
  source:
    id: AveragePooling
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 888
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: stride (increment when sliding over the input). Use a *tuple* to
        specify a per-axis value.
      id: filter_shape
      type: int or tuple of ints
    - description: if *False*, then the pooling operation will be shifted over the
        "valid" area of input, that is, no value outside the area is used. If `pad=True`
        on the other hand, pooling will be applied to all input positions, and positions
        outside the valid region will be excluded from the averaging. Use a *tuple*
        to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - description: the name of the function instance in the network
      id: pad
      type: bool or tuple of bools, defaults to False
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the average-pooling
      operation to it
    summary: "Layer factory function to create an average-pooling layer.\nLike `Convolution()`,\
      \ `AveragePooling()` processes items arranged on an N-dimensional grid, such\
      \ as an image. Typically, each item is a vector. For each item, average-pooling\
      \ computes the element-wise mean over a window (\"receptive field\") of items\
      \ surrounding the item's position on the grid.\nThe size (spatial extent) of\
      \ the receptive field is given by `filter_shape`. E.g. for 2D pooling, `filter_shape`\
      \ should be a tuple of two integers, such as *(5,5)*.\n-[ Example ]-\n>>> f\
      \ = AveragePooling((3,3), strides=2)  # reduce dimensionality by 2, pooling\
      \ over windows of 3x3\n>>> h = Input((32,240,320))  # e.g. 32-dim feature map\n\
      >>> hp = f(h)\n>>> hp.shape  # spatial dimension has been halved due to stride,\
      \ and lost one due to 3x3 window without padding\n    (32, 119, 159)\n>>> f\
      \ = AveragePooling((2,2), strides=2)\n>>> f.update_signature((1,4,4))\n>>> im\
      \ = np.array([[[3, 5, 2, 6], [4, 2, 8, 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  #\
      \ a 4x4 image (feature-map depth 1 for simplicity)\n>>> im\n    array([[[3,\
      \ 5, 2, 6],\n            [4, 2, 8, 3],\n            [1, 6, 4, 7],\n        \
      \    [7, 3, 5, 9]]])\n>>> f([[im]])  # due to strides=2, this computes the averages\
      \ of each 2x2 sub-block\n    array([[[[[ 3.5 ,  4.75],\n              [ 4.25,\
      \  6.25]]]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.AveragePooling
- _type: function
  fullName: cntk.layers.layers.BatchNormalization
  module: cntk.layers.layers
  name: BatchNormalization
  source:
    id: BatchNormalization
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1091
  syntax:
    exceptions: []
    parameters:
    - description: passing 1 means spatially-pooled batch-normalization, where normalization
        values will be tied across all pixel positions; while `None` will normalize
        all elements of the input tensor independently
      id: name
      type: str, optional
    - description: initial value for the `scale` parameter
      id: map_rank
      type: 1 or None
    - description: time constant for smoothing the batch statistics in order to compute
        aggregate estimates for inference.
      id: normalization_time_constant
      type: int, default 5000
    - description: epsilon added to the variance to avoid division by 0
      id: epsilon
      type: float, default 0.00001
    - description: if `True` then use CNTK's own engine instead of NVidia's.
      id: use_cntk_engine
      type: bool, default False
    - description: the name of the function instance in the network
      id: init_scale
      type: float, default 1
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: "Layer factory function to create a batch-normalization layer.\nBatch\
      \ normalization applies this formula to every input element (element-wise):\
      \ `y = (x - batch_mean) / (batch_stddev + epsilon) * scale + bias` where `batch_mean`\
      \ and `batch_stddev` are estimated on the minibatch and `scale` and `bias` are\
      \ learned parameters. TODO: add paper reference\nDuring operation, this layer\
      \ also estimates an aggregate running mean and standard deviation for use in\
      \ inference.\nA `BatchNormalization` layer instance owns its learnable parameter\
      \ tensors and exposes them as attributes `.scale` and `.bias`. The aggregate\
      \ estimates are exposed as attributes `aggregate_mean`, `aggregate_variance`,\
      \ and `aggregate_count`.\n-[ Example ]-\n>>> # BatchNorm on an image with spatial\
      \ pooling\n>>> f = BatchNormalization(map_rank=1)\n>>> f.update_signature((3,480,640))\n\
      >>> f.bias.shape, f.scale.shape  # due to spatial pooling (map_rank=1), there\
      \ are only 3 biases and scales, shared across all pixel positions\n    ((3,),\
      \ (3,))"
    variables: []
  type: Method
  uid: cntk.layers.layers.BatchNormalization
- _type: function
  fullName: cntk.layers.layers.Convolution
  module: cntk.layers.layers
  name: Convolution
  source:
    id: Convolution
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 251
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int, defaults to None
    - description: if *True*, also convolve along the dynamic axis. `filter_shape[0]`
        corresponds to dynamic axis.
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: optional function to apply at the end, e.g. *relu*
      id: activation
      type: Function, defaults to identity
    - description: initial value of weights *W*
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: reduction_rank
      type: int, defaults to 1
    - description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: max_temp_mem_size_in_samples
      type: int, defaults to 0
    - description: When *True*, every position uses the same Convolution kernel.  When
        *False*, you can have a different Convolution kernel per position, but *False*
        is not supported.
      id: transpose
      type: bool, defaults to False
    - description: the layer will have no bias if *False* is passed here
      id: sequential
      type: bool, defaults to False
    - description: initial value of weights *b*
      id: sharing
      type: bool, defaults to True
    - description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: pad
      type: bool or tuple of bools, defaults to False
    - description: When this is *True* this is deconvolution
      id: bias
      type: bool, optional, defaults to True
    - description: Limits the amount of memory for intermiadate convolution results.  A
        value of 0 means, memory is automatically managed.
      id: filter_shape
      type: int or tuple of ints
    - description: the name of the function instance in the network
      id: strides
      type: int or tuple of ints, defaults to 1
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the convolution
      operation to it
    summary: "Layer factory function to create a convolution layer.\nThis implements\
      \ a convolution operation over items arranged on an N-dimensional grid, such\
      \ as pixels in an image. Typically, each item is a vector (e.g. pixel: R,G,B),\
      \ and the result is, in turn, a vector. The item-grid dimensions are referred\
      \ to as the *spatial* dimensions (e.g. dimensions of an image), while the vector\
      \ dimension of the individual items is often called *feature-map depth*.\nFor\
      \ each item, convolution gathers a window (\"receptive field\") of items surrounding\
      \ the item's position on the grid, and applies a little fully-connected network\
      \ to it (the same little network is applied to all item positions). The size\
      \ (spatial extent) of the receptive field is given by `filter_shape`. E.g. to\
      \ specify a 2D convolution, `filter_shape` should be a tuple of two integers,\
      \ such as *(5,5)*; an example for a 3D convolution (e.g. video or an MRI scan)\
      \ would be `filter_shape=(3,3,3)`; while for a 1D convolution (e.g. audio or\
      \ text), `filter_shape` has one element, such as (3,) or just 3.\nThe dimension\
      \ of the input items (input feature-map depth) is not to be specified. It is\
      \ known from the input. The dimension of the output items (output feature-map\
      \ depth) generated for each item position is given by `num_filters`.\nIf the\
      \ input is a sequence, the sequence elements are by default treated independently.\
      \ To convolve along the sequence dimension as well, pass `sequential=True`.\
      \ This is useful for variable-length inputs, such as video or natural-language\
      \ processing (word n-grams). Note, however, that convolution does not support\
      \ sparse inputs.\nBoth input and output items can be scalars intead of vectors.\
      \ For scalar-valued input items, such as pixels on a black-and-white image,\
      \ or samples of an audio clip, specify `reduction_rank=0`. If the output items\
      \ are scalar, pass `num_filters=()` or `None`.\nA `Convolution` instance owns\
      \ its weight parameter tensors *W* and *b*, and exposes them as an attributes\
      \ `.W` and `.b`. The weights will have the shape `(num_filters, input_feature_map_depth,\
      \ *filter_shape)`\n-[ Example ]-\n>>> # 2D convolution of 5x4 receptive field\
      \ with output feature-map depth 128:\n>>> f = Convolution((5,4), 128, activation=C.relu)\n\
      >>> x = Input((3,480,640))  # 3-channel color image\n>>> h = f(x)\n>>> h.shape\n\
      \    (128, 476, 637)\n>>> f.W.shape  # will have the form (num_filters, input_depth,\
      \ *filter_shape)\n    (128, 3, 5, 4)\n>>> # 2D convolution over a one-channel\
      \ black-and-white image, padding, and stride 2 along width dimension\n>>> f\
      \ = Convolution((3,3), 128, reduction_rank=0, pad=True, strides=(1,2), activation=C.relu)\n\
      >>> x = Input((480,640))\n>>> h = f(x)\n>>> h.shape\n    (128, 480, 319)\n>>>\
      \ f.W.shape\n    (128, 1, 3, 3)\n>>> # 3D convolution along dynamic axis over\
      \ a sequence of 2D color images\n>>> from cntk.layers.typing import Sequence,\
      \ Tensor\n>>> f = Convolution((2,5,4), 128, sequential=True, activation=C.relu)\
      \ # over 2 consecutive frames\n>>> x = Input(**Sequence[Tensor[3,480,640]])\
      \  # a variable-length video of 640x480 RGB images\n>>> h = f(x)\n>>> h.shape\
      \   # this is the shape per video frame: 637x476 activation vectors of length\
      \ 128 each\n    (128, 476, 637)\n>>> f.W.shape # (output featuer map depth,\
      \ input depth, and the three filter dimensions)\n    (128, 3, 2, 5, 4)"
    variables: []
  type: Method
  uid: cntk.layers.layers.Convolution
- _type: function
  fullName: cntk.layers.layers.Convolution1D
  module: cntk.layers.layers
  name: Convolution1D
  source:
    id: Convolution1D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 454
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - description: optional function to apply at the end, e.g. *relu*
      id: num_filters
      type: int, defaults to None
    - description: initial value of weights *W*
      id: pad
      type: bool or tuple of bools, defaults to False
    - description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: reduction_rank
      type: int, defaults to 1
    - description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: filter_shape
      type: int or tuple of ints
    - description: the layer will have no bias if *False* is passed here
      id: activation
      type: Function, defaults to identity
    - description: initial value of weights *b*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: strides
      type: int or tuple of ints, defaults to 1
    - description: the name of the function instance in the network
      id: bias
      type: bool, defaults to True
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the convolution
      operation to it
    summary: Layer factory function to create a 1D convolution layer with optional
      non-linearity. Same as *Convolution()* except that filter_shape is verified
      to be 1-dimensional. See *Convolution()* for extensive documentation.
    variables: []
  type: Method
  uid: cntk.layers.layers.Convolution1D
- _type: function
  fullName: cntk.layers.layers.Convolution2D
  module: cntk.layers.layers
  name: Convolution2D
  source:
    id: Convolution2D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 503
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - description: optional function to apply at the end, e.g. *relu*
      id: num_filters
      type: int, defaults to None
    - description: initial value of weights *W*
      id: pad
      type: bool or tuple of bools, defaults to False
    - description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: reduction_rank
      type: int, defaults to 1
    - description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: filter_shape
      type: int or tuple of ints
    - description: the layer will have no bias if *False* is passed here
      id: activation
      type: Function, defaults to identity
    - description: initial value of weights *b*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: strides
      type: int or tuple of ints, defaults to 1
    - description: the name of the function instance in the network
      id: bias
      type: bool, defaults to True
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the convolution
      operation to it
    summary: Layer factory function to create a 2D convolution layer with optional
      non-linearity. Same as *Convolution()* except that filter_shape is verified
      to be 2-dimensional. See *Convolution()* for extensive documentation.
    variables: []
  type: Method
  uid: cntk.layers.layers.Convolution2D
- _type: function
  fullName: cntk.layers.layers.Convolution3D
  module: cntk.layers.layers
  name: Convolution3D
  source:
    id: Convolution3D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 553
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defaults to 0
    - description: optional function to apply at the end, e.g. *relu*
      id: num_filters
      type: int, defaults to None
    - description: initial value of weights *W*
      id: pad
      type: bool or tuple of bools, defaults to False
    - description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: reduction_rank
      type: int, defaults to 1
    - description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: filter_shape
      type: int or tuple of ints
    - description: the layer will have no bias if *False* is passed here
      id: activation
      type: Function, defaults to identity
    - description: initial value of weights *b*
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: set to 0 if input items are scalars (input has no depth axis),
        e.g. an audio signal or a black-and-white image that is stored with tensor
        shape (H,W) instead of (1,H,W)
      id: strides
      type: int or tuple of ints, defaults to 1
    - description: the name of the function instance in the network
      id: bias
      type: bool, defaults to True
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the convolution
      operation to it
    summary: Layer factory function to create a 3D convolution layer with optional
      non-linearity. Same as *Convolution()* except that filter_shape is verified
      to be 3-dimensional. See *Convolution()* for extensive documentation.
    variables: []
  type: Method
  uid: cntk.layers.layers.Convolution3D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose
  module: cntk.layers.layers
  name: ConvolutionTranspose
  source:
    id: ConvolutionTranspose
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 605
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, optional
    - description: number of filters (output feature-map depth), or `()` to denote
        scalar output items (output shape will have no depth axis).
      id: num_filters
      type: int
    - description: optional function to apply at the end, e.g. *relu*
      id: init
      type: scalar or NumPy array or cntk.initializer, default glorot_uniform()
    - description: initial value of weights *W*
      id: activation
      type: Function, optional
    - description: if *False*, then the filter will be shifted over the "valid" area
        of input, that is, no value outside the area is used. If `pad=True` on the
        other hand, the filter will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: init_bias
      type: scalar or NumPy array or cntk.initializer
    - description: stride of the convolution (increment when sliding the filter over
        the input). Use a *tuple* to specify a per-axis value.
      id: reduction_rank
      type: int, default 1
    - description: weight sharing, must be True for now.
      id: max_temp_mem_size_in_samples
      type: int, default 0
    - description: the layer will have no bias if *False* is passed here
      id: sharing
      type: bool, default True
    - description: initial value of weights *b*
      id: pad
      type: bool or tuple of bools, default False
    - description: output shape. When strides > 2, the output shape is non-deterministic.
        User can specify the wanted output shape. Note the specified shape must satisify
        the condition that if a convolution is perform from the output with the same
        setting, the result must have same shape as the input.
      id: output_shape
      type: int or tuple of ints
    - description: must be 1 for now. that is stored with tensor shape (H,W) instead
        of (1,H,W)
      id: bias
      type: bool, optional, default True
    - description: set to a positive number to define the maximum workspace memory
        for convolution.
      id: filter_shape
      type: int or tuple of ints
    - description: the name of the Function instance in the network
      id: strides
      type: int or tuple of ints, default 1
    returntype: ''
    returnvalue: '`Function` that accepts one argument and applies the convolution
      operation to it'
    summary: "Layer factory function to create a convolution transpose layer.\nThis\
      \ implements a convolution_transpose operation over items arranged on an N-dimensional\
      \ grid, such as pixels in an image. Typically, each item is a vector (e.g. pixel:\
      \ R,G,B), and the result is, in turn, a vector. The item-grid dimensions are\
      \ referred to as the *spatial* dimensions (e.g. dimensions of an image), while\
      \ the vector dimensions of the individual items are often called *feature-map\
      \ depth*.\nConvolution transpose is also known as `fractionally strided convolutional\
      \ layers`, or, `deconvolution`. This operation is used in image and language\
      \ processing applications. It supports arbitrary dimensions, strides, and padding.\n\
      The forward and backward computation of convolution transpose is the inverse\
      \ of convolution. That is, during forward pass the input layer's items are spread\
      \ into the output same as the backward spread of gradients in convolution. The\
      \ backward pass, on the other hand, performs a convolution same as the forward\
      \ pass of convolution.\nThe size (spatial extent) of the receptive field for\
      \ convolution transpose is given by `filter_shape`. E.g. to specify a 2D convolution\
      \ transpose, `filter_shape` should be a tuple of two integers, such as *(5,5)*;\
      \ an example for a 3D convolution transpose (e.g. video or an MRI scan) would\
      \ be `filter_shape=(3,3,3)`; while for a 1D convolution transpose (e.g. audio\
      \ or text), `filter_shape` has one element, such as (3,).\nThe dimension of\
      \ the input items (feature-map depth) is not specified, but known from the input.\
      \ The dimension of the output items generated for each item position is given\
      \ by `num_filters`.\nA `ConvolutionTranspose` instance owns its weight parameter\
      \ tensors *W* and *b*, and exposes them as an attributes `.W` and `.b`. The\
      \ weights will have the shape `(input_feature_map_depth, num_filters, *filter_shape)`.\n\
      -[ Example ]-\n>>> # 2D convolution transpose of 3x4 receptive field with output\
      \ feature-map depth 128:\n>>> f = ConvolutionTranspose((3,4), 128, activation=C.relu)\n\
      >>> x = Input((3,480,640))  # 3-channel color image\n>>> h = f(x)\n>>> h.shape\n\
      \    (128, 482, 643)\n>>> f.W.shape  # will have the form (input_depth, num_filters,\
      \ *filter_shape)\n    (3, 128, 3, 4)"
    variables: []
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose1D
  module: cntk.layers.layers
  name: ConvolutionTranspose1D
  source:
    id: ConvolutionTranspose1D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 731
  syntax:
    summary: Layer factory function to create a 1D convolution transpose layer with
      optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
      is verified to be 1-dimensional. See *ConvolutionTranspose()* for extensive
      documentation.
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose1D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose2D
  module: cntk.layers.layers
  name: ConvolutionTranspose2D
  source:
    id: ConvolutionTranspose2D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 757
  syntax:
    summary: Layer factory function to create a 2D convolution transpose layer with
      optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
      is verified to be 2-dimensional. See *ConvolutionTranspose()* for extensive
      documentation.
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose2D
- _type: function
  fullName: cntk.layers.layers.ConvolutionTranspose3D
  module: cntk.layers.layers
  name: ConvolutionTranspose3D
  source:
    id: ConvolutionTranspose3D
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 784
  syntax:
    summary: Layer factory function to create a 3D convolution transpose layer with
      optional non-linearity. Same as *ConvolutionTranspose()* except that filter_shape
      is verified to be 3-dimensional. See *ConvolutionTranspose()* for extensive
      documentation.
  type: Method
  uid: cntk.layers.layers.ConvolutionTranspose3D
- _type: function
  fullName: cntk.layers.layers.Dense
  module: cntk.layers.layers
  name: Dense
  source:
    id: Dense
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 23
  syntax:
    exceptions: []
    parameters:
    - description: vector or tensor dimension of the output of this layer
      id: name
      type: str, defaults to ''
    - description: optional function to apply at the end, e.g. *relu*
      id: map_rank
      type: int, defaults to None
    - description: initial value of weights *W*
      id: shape
      type: int or tuple of ints
    - description: number of inferred axes to add to W (*map_rank* must not be given)
      id: input_rank
      type: int, defaults to None
    - description: expand W to leave exactly *map_rank* axes (*input_rank* must not
        be given)
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: the layer will have no bias if *False* is passed here
      id: activation
      type: Function, defaults to identity
    - description: initial value of weights *b*
      id: bias
      type: bool, optional, defaults to True
    - description: the name of the function instance in the network
      id: init_bias
      type: scalar or NumPy array or cntk.initializer, defualts to 0
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: "Layer factory function to create an instance of a fully-connected linear\
      \ layer of the form *activation(input @ W + b)* with weights *W* and bias *b*,\
      \ and *activation* and *b* being optional. *shape* may describe a tensor as\
      \ well.\nA `Dense` layer instance owns its parameter tensors *W* and *b*, and\
      \ exposes them as attributes `.W` and `.b`.\n-[ Example ]-\n>>> f = Dense(5,\
      \ activation=C.relu)\n>>> x = Input(3)\n>>> h = f(x)\n>>> h.shape\n    (5,)\n\
      >>> f.W.shape\n    (3, 5)\n>>> f.b.value\n    array([ 0.,  0.,  0.,  0.,  0.],\
      \ dtype=float32)\n>>> # activation through default options\n>>> with default_options(activation=C.relu):\n\
      ...     f = Dense(500)"
    variables: []
  type: Method
  uid: cntk.layers.layers.Dense
- _type: function
  fullName: cntk.layers.layers.Dropout
  module: cntk.layers.layers
  name: Dropout
  source:
    id: Dropout
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1020
  syntax:
    exceptions: []
    parameters:
    - description: probability of dropping out an element, mutually exclusive with
        `keep_prob`
      id: name
      type: str, defaults to ''
    - description: probability of keeping an element, mutually exclusive with `dropout_rate`
      id: dropout_rate
      type: float
    - description: the name of the function instance in the network
      id: keep_prob
      type: float
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: 'Layer factory function to create a drop-out layer.

      The dropout rate can be specified as the probability of *dropping* a value (`dropout_rate`).
      E.g. `Dropout(0.3)` means "drop 30% o the activation values." Alternatively,
      it can also be specified as the probability of *keeping* a value (`keep_prob`).

      -[ Example ]-

      >>> f = Dropout(0.2)   # "drop 20% of activations"

      >>> h = Input(3)

      >>> hd = f(h)

      >>> f = Dropout(keep_prob=0.8)   # "keep 80%"

      >>> h = Input(3)

      >>> hd = f(h)'
    variables: []
  type: Method
  uid: cntk.layers.layers.Dropout
- _type: function
  fullName: cntk.layers.layers.Embedding
  module: cntk.layers.layers
  name: Embedding
  source:
    id: Embedding
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 115
  syntax:
    exceptions: []
    parameters:
    - description: vector or tensor dimension of the output of this layer
      id: shape
      type: int or tuple of ints
    - description: (learnable embedding only) initial value of weights *E*
      id: name
      type: str, defaults to ''
    - description: (user-supplied embedding only) the lookup table. The matrix rows
        are the embedding vectors, `weights[i,:]` being the embedding that corresponds
        to input category *i*.
      id: init
      type: scalar or NumPy array or cntk.initializer, defaults to glorot_uniform
    - description: the name of the function instance in the network
      id: weights
      type: NumPy array, mutually exclusive with init, defuats to None
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the embedding operation
      to it
    summary: "Embedding(shape=None, init=glorot_uniform(), weights=None, name=''):\n\
      Layer factory function to create a embedding layer.\nAn embedding is conceptually\
      \ a lookup table. For every input token (e.g. a word or any category label),\
      \ the corresponding entry in in the lookup table is returned.\nIn CNTK, discrete\
      \ items such as words are represented as one-hot vectors. The table lookup is\
      \ realized as a matrix product, with a matrix whose rows are the embedding vectors.\
      \ Note that multiplying a matrix from the left with a one-hot vector is the\
      \ same as copying out the row for which the input vector is 1. CNTK has special\
      \ optimizations to make this operation as efficient as an actual table lookup\
      \ if the input is sparse.\nThe lookup table in this layer is learnable, unless\
      \ a user-specified one is supplied through the `weights` parameter. For example,\
      \ to use an existing embedding table from a file in numpy format, use this:\n\
      <!-- literal_block {\"xml:space\": \"preserve\", \"ids\": [], \"dupnames\":\
      \ [], \"classes\": [], \"backrefs\": [], \"names\": []} -->\n\n````\n\n   Embedding(weights=np.load('PATH.npy'))\n\
      \   ````\nTo initialize a learnable lookup table with a given numpy array that\
      \ is to be used as the initial value, pass that array to the `init` parameter\
      \ (not `weights`).\nAn `Embedding` instance owns its weight parameter tensor\
      \ *E*, and exposes it as an attribute `.E`.\n-[ Example ]-\n>>> # learnable\
      \ embedding\n>>> f = Embedding(5)\n>>> x = Input(3)\n>>> e = f(x)\n>>> e.shape\n\
      \    (5,)\n>>> f.E.shape\n    (3, 5)\n>>> # user-supplied embedding\n>>> f =\
      \ Embedding(weights=[[.5, .3, .1, .4, .2], [.7, .6, .3, .2, .9]])\n>>> f.E.value\n\
      \    array([[ 0.5,  0.3,  0.1,  0.4,  0.2],\n           [ 0.7,  0.6,  0.3, \
      \ 0.2,  0.9]], dtype=float32)\n>>> x = Input(2, is_sparse=True)\n>>> e = f(x)\n\
      >>> e.shape\n    (5,)\n>>> e(C.one_hot([[1], [0], [0], [1]], num_classes=2))\n\
      array([[[ 0.7,  0.6,  0.3,  0.2,  0.9]],\n<BLANKLINE>\n       [[ 0.5,  0.3,\
      \  0.1,  0.4,  0.2]],\n<BLANKLINE>\n       [[ 0.5,  0.3,  0.1,  0.4,  0.2]],\n\
      <BLANKLINE>\n       [[ 0.7,  0.6,  0.3,  0.2,  0.9]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.Embedding
- _type: function
  fullName: cntk.layers.layers.GlobalAveragePooling
  module: cntk.layers.layers
  name: GlobalAveragePooling
  source:
    id: GlobalAveragePooling
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 970
  syntax:
    exceptions: []
    parameters:
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: "Layer factory function to create a global average-pooling layer.\nThe\
      \ global average-pooling operation computes the element-wise mean over all items\
      \ on an N-dimensional grid, such as an image.\nThis operation is the same as\
      \ applying `reduce_mean()` to all grid dimensions.\n-[ Example ]-\n>>> f = GlobalAveragePooling()\n\
      >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8,\
      \ 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for\
      \ simplicity)\n>>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n\
      \            [1, 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])\n   \
      \ array([[[[[ 4.6875]]]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.GlobalAveragePooling
- _type: function
  fullName: cntk.layers.layers.GlobalMaxPooling
  module: cntk.layers.layers
  name: GlobalMaxPooling
  source:
    id: GlobalMaxPooling
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 940
  syntax:
    exceptions: []
    parameters:
    - description: the name of the function instance in the network
      id: name
      type: str, defaults to ''
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: "Layer factory function to create a global max-pooling layer.\nThe global\
      \ max-pooling operation computes the element-wise maximum over all items on\
      \ an N-dimensional grid, such as an image.\nThis operation is the same as applying\
      \ `reduce_max()` to all grid dimensions.\n-[ Example ]-\n>>> f = GlobalMaxPooling()\n\
      >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8,\
      \ 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for\
      \ simplicity)\n>>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n\
      \            [1, 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])\n   \
      \ array([[[[[ 9.]]]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.GlobalMaxPooling
- _type: function
  fullName: cntk.layers.layers.Label
  module: cntk.layers.layers
  name: Label
  source:
    id: Label
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1202
  syntax:
    exceptions: []
    parameters: []
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and returns it with the desired
      name attached
    summary: "Layer factory function to create a dummy layer with a given name. This\
      \ can be used to access an intermediate value flowing through computation.\n\
      -[ Example ]-\n>>> model = Dense(500) >> Label('hidden') >> Dense(10)\n>>> model.update_signature(10)\n\
      >>> intermediate_val = model.hidden\n>>> intermediate_val.shape\n    (500,)"
    variables: []
  type: Method
  uid: cntk.layers.layers.Label
- _type: function
  fullName: cntk.layers.layers.LayerNormalization
  module: cntk.layers.layers
  name: LayerNormalization
  source:
    id: LayerNormalization
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1156
  syntax:
    exceptions: []
    parameters:
    - description: initial value for the `scale` parameter
      id: name
      type: str, optional
    - description: initial value for the `bias` parameter
      id: epsilon
      type: float, default 0.00001
    - description: epsilon added to the standard deviation to avoid division by 0
      id: initial_scale
      type: float, default 1
    - description: the name of the Function instance in the network
      id: initial_bias
      type: float, default 0
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the operation to
      it
    summary: "Layer factory function to create a function that implements layer normalization.\n\
      Layer normalization applies this formula to every input element (element-wise):\
      \ `y = (x - mean(x)) / (stddev(x) + epsilon) * scale + bias` where `scale` and\
      \ `bias` are learned scalar parameters. TODO: add paper reference\n-[ Example\
      \ ]-\n>>> f = LayerNormalization(initial_scale=2, initial_bias=1)\n>>> f.update_signature(4)\n\
      >>> f([np.array([[4,0,0,4]])])  # result has mean 1 and standard deviation 2,\
      \ reflecting the initial values for scale and bias\n    array([[[ 2.99999, -0.99999,\
      \ -0.99999,  2.99999]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.LayerNormalization
- _type: function
  fullName: cntk.layers.layers.MaxPooling
  module: cntk.layers.layers
  name: MaxPooling
  source:
    id: MaxPooling
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 836
  syntax:
    exceptions: []
    parameters:
    - description: shape (spatial extent) of the receptive field, *not* including
        the input feature-map depth. E.g. (3,3) for a 2D convolution.
      id: name
      type: str, defaults to ''
    - description: stride (increment when sliding over the input). Use a *tuple* to
        specify a per-axis value.
      id: filter_shape
      type: int or tuple of ints
    - description: if *False*, then the pooling operation will be shifted over the
        "valid" area of input, that is, no value outside the area is used. If `pad=True`
        on the other hand, pooling will be applied to all input positions, and positions
        outside the valid region will be considered containing zero. Use a *tuple*
        to specify a per-axis value.
      id: strides
      type: int or tuple of ints, defaults to 1
    - description: the name of the function instance in the network
      id: pad
      type: bool or tuple of bools, defaults to False
    returntype: cntk.ops.functions.Function
    returnvalue: A function that accepts one argument and applies the max-pooling
      operation to it
    summary: "Layer factory function to create a max-pooling layer.\nLike `Convolution()`,\
      \ `MaxPooling()` processes items arranged on an N-dimensional grid, such as\
      \ an image. Typically, each item is a vector. For each item, max-pooling computes\
      \ the element-wise maximum over a window (\"receptive field\") of items surrounding\
      \ the item's position on the grid.\nThe size (spatial extent) of the receptive\
      \ field is given by `filter_shape`. E.g. for 2D pooling, `filter_shape` should\
      \ be a tuple of two integers, such as *(5,5)*.\n-[ Example ]-\n>>> f = MaxPooling((3,3),\
      \ strides=2)  # reduce dimensionality by 2, pooling over windows of 3x3\n>>>\
      \ h = Input((32,240,320))  # e.g. 32-dim feature map\n>>> hp = f(h)\n>>> hp.shape\
      \  # spatial dimension has been halved due to stride, and lost one due to 3x3\
      \ window without padding\n    (32, 119, 159)\n>>> f = MaxPooling((2,2), strides=2)\n\
      >>> f.update_signature((1,4,4))\n>>> im = np.array([[[3, 5, 2, 6], [4, 2, 8,\
      \ 3], [1, 6, 4, 7], [7, 3, 5, 9]]])  # a 4x4 image (feature-map depth 1 for\
      \ simplicity)\n>>> im\n    array([[[3, 5, 2, 6],\n            [4, 2, 8, 3],\n\
      \            [1, 6, 4, 7],\n            [7, 3, 5, 9]]])\n>>> f([[im]])  # due\
      \ to strides=2, this picks the max out of each 2x2 sub-block\n    array([[[[[\
      \ 5.,  8.],\n              [ 7.,  9.]]]]], dtype=float32)"
    variables: []
  type: Method
  uid: cntk.layers.layers.MaxPooling
- _type: function
  fullName: cntk.layers.layers.MaxUnpooling
  module: cntk.layers.layers
  name: MaxUnpooling
  source:
    id: MaxUnpooling
    path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
    remote:
      branch: master
      path: root/anaconda3/envs/cntk-py35/lib/python3.5/site-packages/cntk/layers/layers.py
      repo: null
    startLine: 1002
  syntax:
    summary: ''
  type: Method
  uid: cntk.layers.layers.MaxUnpooling
